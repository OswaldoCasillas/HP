name: Palacio Scraper (DISCO + ALL_CHANGES CSV)

on:
  schedule:
    # 08:00 y 20:00 UTC ‚âà 02:00 y 14:00 CDMX (seg√∫n DST)
    - cron: "0 8,20 * * *"
  workflow_dispatch:
    inputs:
      run_all:
        description: "Ejecutar TODAS las categor√≠as"
        type: boolean
        default: true
        required: true
      category:
        description: "Categor√≠a √∫nica (si run_all = false). Ej: juguetes"
        type: string
        required: false
        default: ""
      start:
        description: "Offset inicial start="
        type: string
        required: false
        default: ""
      page_size:
        description: "Tama√±o de p√°gina sz="
        type: string
        required: false
        default: ""
      page_step:
        description: "Salto de start"
        type: string
        required: false
        default: ""
      max_pages:
        description: "M√°ximo de p√°ginas"
        type: string
        required: false
        default: ""
      highlight:
        description: "Umbral % para resaltar (XLSX)"
        type: string
        required: false
        default: "51"

permissions:
  contents: read

concurrency:
  group: palacio-scraper
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            # openpyxl para leer las hojas CHANGES de los .xlsx
            pip install requests pandas beautifulsoup4 xlsxwriter openpyxl pyarrow
          fi

      - name: Show runner time (UTC)
        run: date -u

      - name: Run scraper
        shell: bash
        run: |
          set -euo pipefail

          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            RUN_ALL="${{ github.event.inputs.run_all }}"
            CATEGORY="${{ github.event.inputs.category }}"
            START="${{ github.event.inputs.start }}"
            PAGE_SIZE='${{ github.event.inputs.page_size }}'
            PAGE_STEP='${{ github.event.inputs.page_step }}'
            MAX_PAGES='${{ github.event.inputs.max_pages }}'
            HIGHLIGHT='${{ github.event.inputs.highlight }}'
          else
            RUN_ALL="true"
            CATEGORY=""
            START=""
            PAGE_SIZE=""
            PAGE_STEP=""
            MAX_PAGES=""
            HIGHLIGHT="51"
          fi

          ARGS=""
          if [[ "${RUN_ALL}" == "true" || "${RUN_ALL}" == "True" ]]; then
            ARGS+=" --all"
          else
            if [[ -z "${CATEGORY}" ]]; then
              echo "‚ùå Debes indicar 'category' cuando run_all=false."
              exit 1
            fi
            ARGS+=" -c ${CATEGORY}"
          fi

          [[ -n "${START}" ]] && ARGS+=" --start ${START}"
          [[ -n "${PAGE_SIZE}" ]] && ARGS+=" --page-size ${PAGE_SIZE}"
          [[ -n "${PAGE_STEP}" ]] && ARGS+=" --page-step ${PAGE_STEP}"
          [[ -n "${MAX_PAGES}" ]] && ARGS+=" --max-pages ${MAX_PAGES}"
          [[ -n "${HIGHLIGHT}" ]] && ARGS+=" --highlight ${HIGHLIGHT}"

          echo "‚ñ∂ python palacio_category_snapshot.py ${ARGS}"
          python palacio_category_snapshot.py ${ARGS}

      - name: Build ALL_CHANGES CSV (desde los XLSX)
        if: always()
        run: |
          python - << 'PY'
          import pandas as pd, glob, os, pathlib
          base = pathlib.Path("out_palacio")
          files = glob.glob(str(base / "**/*_snapshot_*.xlsx"), recursive=True)
          rows = []
          for f in files:
            try:
              df = pd.read_excel(f, sheet_name="CHANGES", engine="openpyxl")
            except Exception:
              continue
            # si solo trae columna "info" (mensaje "Sin cambios..."), saltamos
            if df.empty or (set(df.columns) == {"info"}):
              continue
            cat = pathlib.Path(f).parts[-3]  # out_palacio/<prefix>/<YYYY-MM>/file.xlsx
            df.insert(0, "category", cat)
            df.insert(1, "snapshot_file", os.path.basename(f))
            rows.append(df)
          if rows:
            out = pd.concat(rows, ignore_index=True)
            out_dir = base
            out_dir.mkdir(parents=True, exist_ok=True)
            out_path = out_dir / f"ALL_CHANGES_{os.environ.get('GITHUB_RUN_ID','local')}.csv"
            out.to_csv(out_path, index=False, encoding="utf-8-sig")
            print(f"‚úì Consolidado guardado en {out_path}")
          else:
            print("‚ö†Ô∏è No se encontraron filas reales en CHANGES para consolidar.")
          PY

      - name: Upload outputs (out_palacio/)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: out_palacio-${{ github.run_id }}
          path: out_palacio/**
          if-no-files-found: warn
          retention-days: 10

      - name: Zip out_palacio
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          cd "${{ github.workspace }}"
          if [ -d "out_palacio" ]; then
            zip -r "out_palacio_${{ github.run_id }}.zip" out_palacio
            ls -lh "out_palacio_${{ github.run_id }}.zip"
          else
            echo "‚ö†Ô∏è No existe out_palacio/, no se genera ZIP."
            echo "no outputs" > "out_palacio_${{ github.run_id }}.txt"
          fi

      - name: Email ZIP + ALL_CHANGES via Gmail
        if: always()
        env:
          EMAIL_HOST: smtp.gmail.com
          EMAIL_PORT: "587"
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASS: ${{ secrets.EMAIL_PASS }}
          EMAIL_TO:   ${{ secrets.EMAIL_TO }}
        run: |
          python - << 'PY'
          import os, smtplib, ssl, mimetypes, pathlib
          from email.message import EmailMessage

          run_id = os.environ.get("GITHUB_RUN_ID")
          zip_path = f"out_palacio_{run_id}.zip"
          placeholder = f"out_palacio_{run_id}.txt"
          all_changes = f"out_palacio/ALL_CHANGES_{run_id}.csv"

          attachments = []
          if pathlib.Path(zip_path).exists():
              attachments.append(zip_path)
          elif pathlib.Path(placeholder).exists():
              attachments.append(placeholder)

          if pathlib.Path(all_changes).exists():
              attachments.append(all_changes)

          user = os.environ.get("EMAIL_USER","")
          pwd  = os.environ.get("EMAIL_PASS","")
          to   = os.environ.get("EMAIL_TO","")

          if not user or not pwd or not to:
            print("‚ö†Ô∏è Falta EMAIL_USER/EMAIL_PASS/EMAIL_TO; no se env√≠a correo.")
            raise SystemExit(0)

          msg = EmailMessage()
          msg["From"] = user
          msg["To"] = to
          msg["Subject"] = "[Scraper] out_palacio + ALL_CHANGES"
          msg.set_content("Adjunto:\n- ZIP con out_palacio\n- ALL_CHANGES CSV consolidado (si hubo cambios)")

          for p in attachments:
            ctype, _ = mimetypes.guess_type(p)
            if not ctype: ctype = "application/octet-stream"
            maintype, subtype = ctype.split("/", 1)
            with open(p, "rb") as f:
              msg.add_attachment(f.read(), maintype=maintype, subtype=subtype, filename=os.path.basename(p))

          cx = smtplib.SMTP(os.environ["EMAIL_HOST"], int(os.environ["EMAIL_PORT"]))
          cx.ehlo(); cx.starttls(context=ssl.create_default_context()); cx.ehlo()
          cx.login(user, pwd)
          cx.send_message(msg)
          cx.quit()
          print("üìß Enviado adjuntos:", ", ".join(attachments) if attachments else "(ninguno)")
          PY
